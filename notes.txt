!!Important!!
This document is version-controlled, so don't put anything sensitive here!!!
!!

10/10/21
    - Starting over, once again, from scratch. this time deployment comes first, until i reach some arbitrary stage of stability.
    - the goal here is, again: deployment first. until i can feel confident that local changes will propogate remotely, i test on live
    server first. not efficient but it's the only way at the moment to avoid these boondoggles where i hit a wall and need to start over.

    - Road map (Add notes below, keep this clean):
        (Scaffolding)
        - [X] LIVE hello world
        - [X] postgres in production
        - [X] postgres in development
        - [X] development/production settings (bonus: local docker works too)
        - [X] templates
        - [X] Sentry
        - [X] version control
        - [X] static files
        - [X] logging
        - [-] TESTING (ongoing)
        (App features)
        - [ ] Image uploader
        - [ ] Users/accounts app
        - [ ] Auctions site
        - [ ] Comments
        - [ ] Stripe payment
        - [ ] Email integration

    Roadmap notes:
    - Dev/prod settings:
        - see if django-environ works on both environments. definitely easiest to use .env file locally, so that'd be preferred
        if it also works on the server.
            - Yes! i guess the server also includes env variables in a .env file so it's able to read it. convenient.
        - !Important!
        FIXED>>>>>>>>>
            - The way it's set up, I have settings that will work either for live production (deployed to fly.io) OR
            running locally via manage.py runserver. Creating a local docker image/container does not seem to work.
            - To fix this i would need a third suite of settings to specify, for instance, ALLOWED_HOSTS=['0.0.0.0:8000']
            - Choosing between which settings to load could be done by, once again, returning to an __init__ that checks for an
            environment variable. but i like how simple/clean the current setup is (if there's a local settings file, load it; 
            that file will override any values so that it works locally).
            - another try condition that looks for a local_docker_settings.py file wouldn't work: it would be excluded from 
            .dockerignore and therefore deployed to production. 
            - Maybe one solution is to simply check for a single environment variable that flags certain values to be specific to 
            a local docker container. 
        <<<<<<<<<FIXED
            - simply added '0.0.0.0' to ALLOWED_HOSTS and a local docker container runs fine so far. of course it will not be using
            any local settings; i.e. will be using production APIs etc. but good for staging.
                - not quite: local docker build wasn't working because USE_S3 was set to false, meaning it was attempting to load
                local static files, but collecstatic doesn't get run during the build (because it fails during deployment). 
                changing USE_S3 to True seems to have worked. 
                - so the only way to run Docker locally is to set USE_S3 to True so that it loads statics from Amazon. i can see
                problems ahead when new statics are added without being collected first. 
        FIXED FOR REAL
        - started using whitenoise for serving static files, which works in all environments.
    - Postgres: seems to be working (tested with creating superuser and logging into /admin/)
    - Version control
        - renamed mocktions2, created a new "mocktions" repo.
    - Staticfiles
        - it appears that Docker does not have access to environment variables at build-time. therefore, collecting static as a
        command in the Dockerfile will fail, since it relies on environment variables.
        - the solution is to build image without collecting static, then run collectstatic via the ssh console manually.
        - now, those environment variables COULD be added to fly.toml, maybe; it would just have to be ommitted from versioning
        control, which for now would probably be less convenient than just manually running collectstatic.
    - Logging
        - sentry automatically captures logs at level error or higher (maybe warning too?) but even so they are still listed as
        "info" level in the sentry dashboard. 
        - they are also always listed as "info" in the monitoring tab of the fly.io app's page.
        - trying to log an info level message is ignored.
        - happens regardless of whether or not django's own logging is setup or not.
        - sentry's set_level("info") does nothing

10/18
    >>>>>>> Abandoned for now
        What I'd like to do is create a middleware that, on every page load, checks to see if I am logged in (me, specifically) and 
        to only display the page if I am, redirecting to a "Coming Soon" page if not. that way i can keep pushing to production and 
        checking on how things are working there while maintaining a consistent, static message to visitors (not that there's anyone
        visiting...).
            - maybe check for admin user status, that might be built in already
            - maybe add a setting that specifies a permission level; add a decorator that checks for that permission level
                - the reason being if i'm adding this decorator to every view it'd be easier to just change the permission to public
                - instead of manually deleting them all
    <<<<<<<
    Messages: to replace my original notification system, use the built-in messaging middleware.
        - potentially override storages to make use of DB?

10/20
    Important! When running a docker container locally, add --network=host in order to use the database!!! ah this was so annoying to
    try to figure out!!!
        sudo docker run --name mocktions -p 8000:8000 --network=host mocktions

10/26
    - TESTING
        - definitely easier to initiate tests after every addition to the codebase. do not let this get too far behind!!!!
        - all test methods within test classes MUST begin with "test_" to be discoverable.

11/28
    - Access shell to run tests within container:
    - exec to run arbitrary commands
    - start container, then run sudo docker exect -it <container_name> sh to start a shell

1/18
    - building selenium page objects and tests:
        - stale element? refresh the page object

1/19
    run coverage:
        coverage run --source='.' manage.py test myapp
        app is optional there obviously. full command omitting the unnecessary stuff:
            coverage run --source='.' --omit="manage.py","*/testing/*","*/asgi.py","*/wsgi.py" manage.py test

1/30
    django_backblaze_b2 has CHANGED MY LIFE. once i figured out that, as a storage class, i can just call it as storage in my model class and it would handle uploading to my b2 bucket.... incredible. so i don't have to deal with pre-signed URL BS or anything... i'm in awe. and django-cleanup works as well to handle deleting the objects from the bucket. so easy. my goodness, i'm so psyched.

    uploading images:
    just use an ImageField in a form, or a CreateView. the model storage property is set to BackblazeB2Storage (or PublicStorage or whatever) which automatically uploads to B2. so that's taken care of.

    to access images after uploading:
    {% static object.image_field.name %}
    static appends the https://backblazeb2.yadda.yadda/" and then image_field.name appends the relative path, filename, and extension.

1/31
    ok i think i need to revamp this a bit.
    uploaded images should be "media" not static files.
    static files get saved to their own directory and are accessed with {% static %}, which appends the full URL for the b2 bucket where they are 
    kept.

    media files should get uploaded to their own bucket/directory. they are accessed in the template with {{ MEDIA_URL }}{{ object.image_field.name }} which should parse as the full file URL in the bucket.

    OR

    i guess, apparently, i can still use the {% static %} tag and it will load 
    media files that have been uploaded to their own directory in the bucket, 
    separately from regular static files. i guess!! this is sorta convenient for
    production's sake, but it doesn't solve my problem of wanting to take the
    django_backblaze_b2 package out of the picture for doing unit tests because
    the cachetable seems to break the testing environment.

    am i imagining it or are things really slow now? all the files are being routed through a local /b2/ url - is that why? seems like overhead. for a minute there they were being loaded directly from the bucket and it seemed
    faster (makes sense).

    just deployed this to Fly and in production i don't notice any lag - seems
    like everything is being cached correctly. but also, just noticed that in 
    prod it's loading from the full file URL, not a relative URL via /b2/ so 
    that probably does explain it. but why? i deployed straight from what i 
    have saved.

    maybe because locally, debug=true and therefore Django doesn't serve media
    the same?

    test: USE_LOCAL = False, DEBUG = False.
        - result: fast, loading from full file URL
    test: USE_LOCAL = False, DEBUG = True.
        - results: no change, still loading from full file URL.
    test: USE_LOCAL = True, DEBUG = True
        - results: attemping to load files from /staticfiles/

    the MEDIA_URL and STATIC_URL seem to be ignored.

    So one thing I've noticed:
    in the template, there are two ways to denote the src attribute of an img tag:
        1) src="{% static object.image_field.name %}"
        2) src="{{ object.image_field.url }}"

    1) will load the file directly from the B2 bucket and seems fastest.
    2) will load it via the /b2/ url routing. why use that? the docs for django_backblaze_b2 state that these url routes are for controlling access
    to objects that may or may not be public/private. is that important to me? 

2/20
    for unit tests, run in parallel with the --parallel flag, otherwise there 
    are strange errors (duplicate usernames or filenotfound for images that 
    definitely exist)

2/22
    starting up a DRF project for practice. feels bad taking time away from developing (and the inevitable refactoring if this provides the functionality i am looking for) but i do suspect this is the way i want to set up the Images app, which requires only URL endpoints for CRUD operations and doesn't need views or anything.

3/14
    OOb swap with HTMX for replacing only the most recently uploaded image
