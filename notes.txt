!!Important!!
This document is version-controlled, so don't put anything sensitive here!!!
!!

10/10/21
    - Starting over, once again, from scratch. this time deployment comes first, until i reach some arbitrary stage of stability.
    - the goal here is, again: deployment first. until i can feel confident that local changes will propogate remotely, i test on live
    server first. not efficient but it's the only way at the moment to avoid these boondoggles where i hit a wall and need to start over.

    - Road map (Add notes below, keep this clean):
        (Scaffolding)
        - [X] LIVE hello world
        - [X] postgres in production
        - [X] postgres in development
        - [X] development/production settings (bonus: local docker works too)
        - [X] templates
        - [X] Sentry
        - [X] version control
        - [X] static files
        - [X] logging
        - [-] TESTING (ongoing)
        (App features)
        - [ ] Image uploader
        - [ ] Users/accounts app
        - [ ] Auctions site
        - [ ] Comments
        - [ ] Stripe payment
        - [ ] Email integration

    Roadmap notes:
    - Dev/prod settings:
        - see if django-environ works on both environments. definitely easiest to use .env file locally, so that'd be preferred
        if it also works on the server.
            - Yes! i guess the server also includes env variables in a .env file so it's able to read it. convenient.
        - !Important!
        FIXED>>>>>>>>>
            - The way it's set up, I have settings that will work either for live production (deployed to fly.io) OR
            running locally via manage.py runserver. Creating a local docker image/container does not seem to work.
            - To fix this i would need a third suite of settings to specify, for instance, ALLOWED_HOSTS=['0.0.0.0:8000']
            - Choosing between which settings to load could be done by, once again, returning to an __init__ that checks for an
            environment variable. but i like how simple/clean the current setup is (if there's a local settings file, load it; 
            that file will override any values so that it works locally).
            - another try condition that looks for a local_docker_settings.py file wouldn't work: it would be excluded from 
            .dockerignore and therefore deployed to production. 
            - Maybe one solution is to simply check for a single environment variable that flags certain values to be specific to 
            a local docker container. 
        <<<<<<<<<FIXED
            - simply added '0.0.0.0' to ALLOWED_HOSTS and a local docker container runs fine so far. of course it will not be using
            any local settings; i.e. will be using production APIs etc. but good for staging.
                - not quite: local docker build wasn't working because USE_S3 was set to false, meaning it was attempting to load
                local static files, but collecstatic doesn't get run during the build (because it fails during deployment). 
                changing USE_S3 to True seems to have worked. 
                - so the only way to run Docker locally is to set USE_S3 to True so that it loads statics from Amazon. i can see
                problems ahead when new statics are added without being collected first. 
        FIXED FOR REAL
        - started using whitenoise for serving static files, which works in all environments.
    - Postgres: seems to be working (tested with creating superuser and logging into /admin/)
    - Version control
        - renamed mocktions2, created a new "mocktions" repo.
    - Staticfiles
        - it appears that Docker does not have access to environment variables at build-time. therefore, collecting static as a
        command in the Dockerfile will fail, since it relies on environment variables.
        - the solution is to build image without collecting static, then run collectstatic via the ssh console manually.
        - now, those environment variables COULD be added to fly.toml, maybe; it would just have to be ommitted from versioning
        control, which for now would probably be less convenient than just manually running collectstatic.
    - Logging
        - sentry automatically captures logs at level error or higher (maybe warning too?) but even so they are still listed as
        "info" level in the sentry dashboard. 
        - they are also always listed as "info" in the monitoring tab of the fly.io app's page.
        - trying to log an info level message is ignored.
        - happens regardless of whether or not django's own logging is setup or not.
        - sentry's set_level("info") does nothing

10/18
    >>>>>>> Abandoned for now
        What I'd like to do is create a middleware that, on every page load, checks to see if I am logged in (me, specifically) and 
        to only display the page if I am, redirecting to a "Coming Soon" page if not. that way i can keep pushing to production and 
        checking on how things are working there while maintaining a consistent, static message to visitors (not that there's anyone
        visiting...).
            - maybe check for admin user status, that might be built in already
            - maybe add a setting that specifies a permission level; add a decorator that checks for that permission level
                - the reason being if i'm adding this decorator to every view it'd be easier to just change the permission to public
                - instead of manually deleting them all
    <<<<<<<
    Messages: to replace my original notification system, use the built-in messaging middleware.
        - potentially override storages to make use of DB?

10/20
    Important! When running a docker container locally, add --network=host in order to use the database!!! ah this was so annoying to
    try to figure out!!!
        sudo docker run --name mocktions -p 8000:8000 --network=host mocktions

10/26
    - TESTING
        - definitely easier to initiate tests after every addition to the codebase. do not let this get too far behind!!!!
        - all test methods within test classes MUST begin with "test_" to be discoverable.

11/28
    - Access shell to run tests within container:
    - exec to run arbitrary commands
    - start container, then run sudo docker exec -it <container_name> sh to start a shell

1/18
    - building selenium page objects and tests:
        - stale element? refresh the page object

1/19
    run coverage:
        coverage run --source='.' manage.py test myapp
        app is optional there obviously. full command omitting the unnecessary stuff:
            coverage run --source='.' --omit="manage.py","*/testing/*","*/asgi.py","*/wsgi.py" manage.py test

1/30
    django_backblaze_b2 has CHANGED MY LIFE. once i figured out that, as a storage class, i can just call it as storage in my model class and it would handle uploading to my b2 bucket.... incredible. so i don't have to deal with pre-signed URL BS or anything... i'm in awe. and django-cleanup works as well to handle deleting the objects from the bucket. so easy. my goodness, i'm so psyched.

    uploading images:
    just use an ImageField in a form, or a CreateView. the model storage property is set to BackblazeB2Storage (or PublicStorage or whatever) which automatically uploads to B2. so that's taken care of.

    to access images after uploading:
    {% static object.image_field.name %}
    static appends the https://backblazeb2.yadda.yadda/" and then image_field.name appends the relative path, filename, and extension.

1/31
    ok i think i need to revamp this a bit.
    uploaded images should be "media" not static files.
    static files get saved to their own directory and are accessed with {% static %}, which appends the full URL for the b2 bucket where they are 
    kept.

    media files should get uploaded to their own bucket/directory. they are accessed in the template with {{ MEDIA_URL }}{{ object.image_field.name }} which should parse as the full file URL in the bucket.

    OR

    i guess, apparently, i can still use the {% static %} tag and it will load 
    media files that have been uploaded to their own directory in the bucket, 
    separately from regular static files. i guess!! this is sorta convenient for
    production's sake, but it doesn't solve my problem of wanting to take the
    django_backblaze_b2 package out of the picture for doing unit tests because
    the cachetable seems to break the testing environment.

    am i imagining it or are things really slow now? all the files are being routed through a local /b2/ url - is that why? seems like overhead. for a minute there they were being loaded directly from the bucket and it seemed
    faster (makes sense).

    just deployed this to Fly and in production i don't notice any lag - seems
    like everything is being cached correctly. but also, just noticed that in 
    prod it's loading from the full file URL, not a relative URL via /b2/ so 
    that probably does explain it. but why? i deployed straight from what i 
    have saved.

    maybe because locally, debug=true and therefore Django doesn't serve media
    the same?

    test: USE_LOCAL = False, DEBUG = False.
        - result: fast, loading from full file URL
    test: USE_LOCAL = False, DEBUG = True.
        - results: no change, still loading from full file URL.
    test: USE_LOCAL = True, DEBUG = True
        - results: attemping to load files from /staticfiles/

    the MEDIA_URL and STATIC_URL seem to be ignored.

    So one thing I've noticed:
    in the template, there are two ways to denote the src attribute of an img tag:
        1) src="{% static object.image_field.name %}"
        2) src="{{ object.image_field.url }}"

    1) will load the file directly from the B2 bucket and seems fastest.
    2) will load it via the /b2/ url routing. why use that? the docs for django_backblaze_b2 state that these url routes are for controlling access
    to objects that may or may not be public/private. is that important to me? 

2/20
    for unit tests, run in parallel with the --parallel flag, otherwise there 
    are strange errors (duplicate usernames or filenotfound for images that 
    definitely exist)

2/22
    starting up a DRF project for practice. feels bad taking time away from developing (and the inevitable refactoring if this provides the functionality i am looking for) but i do suspect this is the way i want to set up the Images app, which requires only URL endpoints for CRUD operations and doesn't need views or anything.

3/14
    OOb swap with HTMX for replacing only the most recently uploaded image

    So, the form marks up its swap in reference to itself only:
    <form hx-swap="outerHTML" hx-post="...">
    The returned HTML will find the form element and swap it in the page as expected.

    For the list of images, the enter list including the container with the swap strategy
    gets returned:
        <ul hx-swap-oob="afterbegin">
            <li><!-- new item --></li>
        </ul>
    Because of the "afterbegin" strategy, only the <li> element gets swapped in, at the beginning.

    So the server response would look like this:

    response = """
        <form hx-swap="outerHTML" hx-post="image-create/">
            <input type="file">
            <button>Upload</button>
        </form>
        <div id="image-list" hx-swap-oob="afterbegin">
            <img src="1.jpg">
        </div>
    """
3/30
    Setting up Images to be able to be dropped into any other page by adding:
        {% include "images/html/includes/main.html" with max_uploads=int multiple=bool %}
    and,
        <select id="id_image_upload_list" name="image_upload_ids" class="d-none" hx-swap-oob="afterbegin"></select>
    into any template. the images get uploaded and their IDs are appended to the select element
    which can be submitted with any creation form to set foreign-keys to the associated images.
        img_ids: List[int] = request.getlist("image_upload_ids")
    
    max uploads initialized in {% include %}; list() renders template with max_uploads in context
    upload_response sets hidden input tags with remaining uploads value
    create reduces uploads by one 
    delete increases uploads by one 
    list() counts uploaded images and reduces uploads accordingly.

    considering a ImageSet model that links via FK to image IDs. that would obviate needing to
    load up a hidden <select> element with new image IDs. just initialize an ImageSet when the 
    upload form is first rendered and link new uploads to it. 

    how about, when wanting to implement an upload form, initializing it in the view by creating
    a new instance of the ModelViewSet which can provide the ImageSet ID as well as the HTML.

    index():
        image_upload = ImageUpload(max_uploads = 10, allow_multiple = True)
        image_set: ImageSet = image_upload.get_image_set()
        image_form_html = image_upload.get_html()

4/2
    ok so none of that shit is working and i think i want to go back to as simple an implementation as possible.

    since i'm ONYL returning HTML via HX, just simple function views are probably sufficient.

    but I have requirements:
        "images" needs to be able to be dropped into any other app.
            - instantiate a class that provides the images (collected as an imageset) and the initial HTML to insert
            into a template.
            - all image uploading and control occurs independently by the images app. it just needs to be dropped into
            another app's template.
            - the other app access the uploaded images via an imageset that is exposed by the ImageUploader 
            
    so the plan:
        - images gets loaded with an {% include %} tag like before.
        - the include has a <div> that calls a GET request for the form. in this way the form loads separately from 
        the page. this is so that the configurations can be set (max uploads).
        - headers get added to each HX request tracking the number of uploads 

        Done:
            (arbitrary template) includes main.html with max_uploads and allow_multiple.
            main.html has a div that makes a GET request for the upload form, including headers for max_uploads and allow_multiple 
            uploader.py mixin captures those headers and adds them to context dictionary for any class that subclasses HXUploadCounter.

        Todo:
            mixing the Imageset variable
            display images and load already-uploaded images to form 

        Done:
            All necessary headers (max_uploads, allow_multiple, imageset) are rendered when the form first loads and thereafter 
            affixed to each HTMX request. They also get re-rendered each time upload_response.html gets rendered, so they can 
            be modified.

4/4
    why tf am i tracking max uploads, and allow multiple, in headers? just make "max_uploads" a field on imageset and check 
    the number of uploads off of that? duh!!

    HX_LoadForm captures the max size in kwargs via url param, creates an imageset object with that max size, adds imageset 
    to template context. form template returns imageset pk with uploaded image. also makes it easier to display already-uploaded 
    images by iterating over imageset.images.all 

4/20
    currently debating separating out the listing part of creating a listing from the uploading images part.
    i think i'd like it combined in one. the difficulty was that uploading images involves its own little sub-forms.
    not really a problem since the sub-forms all update the FKs on the imageset, and the imageset remains static in the main form, 
    so the component forms don't need to be nested. the submit button can even be separated from the main form with 
    valid html5 by using the form= attribute and specifying the id of the main form. 

    now need to figure out how to validate that there are enough and not too many images. hoping to not use JS but
    that may be easiest.

    ok, so one thing is clear: validating images via the listing form isn't the way to go: there's no way 
    to comfortable reload previously-uploaded images and maintain a filled-out form (including images) with 
    errors displayed. it also makes some semantic sense that the image uploader should validate itself. 

    however, how do we prevent the submit button from activating? it brings me back to a two-part upload process.
    which i don't want to do. 

    but what if a submit button on the images, which validates the images, swaps the submit button for the 
    listing form, from a deactivated state to an activated state, if images are valid? 

    the problem:
        if too many/few images are uploaded and the submit button is clicked, all uploaded images are lost 
        and the form is returned with an error message.

    what it should do:
        if too many/few images are uploaded and the submit button is clicked, all uploaded images should 
        remain and the form is returned with an error message. 

    one possible cause:
        the listing create template ALWAYS loads a fresh image upload include; it has no way to retrieve an 
        existing imageset.
    
    one possible solution:
        if an imageset exists for this listing, add it to context data and check for it. 

    a truly unbelievable amount of errors resulted in what seemed like a simple fix.
    i mean, it was like my computer had suddenly been possessed by ghosts. i slammed the lid shut.


    New tactic.
    ONCE AGAIN MOVING TO A TWO PART LISTING CREATION PROCESS.

    first instantiate a new imageset object. set its value to the ListingForm's initial values.
    load form. fill out form. submit, validate, return redirect to images. all that's needed then is 
    the imageset id. will need a flag on the listing to indicate it's not posted yet.

    ok actually.... back to a one-part listing form. basically did the above (instantiate an imageset 
    object and use it to populate initial value on a listing form). in the template, access the imageset 
    id by form value: form.imageset.value. also, the validators for the imageset work fine when they're
    part of the listing form (checked on listing creation, not imageset creation), just remember to 
    return the data after validating. 